<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.74">
<link rel="alternate" type="application/rss+xml" href="/CoastTrain/blog/rss.xml" title="CoastTrain Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/CoastTrain/blog/atom.xml" title="CoastTrain Blog Atom Feed"><title data-react-helmet="true">Overview | CoastTrain</title><meta data-react-helmet="true" property="og:url" content="https://dbuscombe-usgs.github.io/CoastTrain/docs/Version 1: March 2022/overview"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Overview | CoastTrain"><meta data-react-helmet="true" name="description" content="While there are many potential types of imagery we could use, the Coast Train project has settled on the following types of imagery because they collectively represent a majority of use-cases and scales."><meta data-react-helmet="true" property="og:description" content="While there are many potential types of imagery we could use, the Coast Train project has settled on the following types of imagery because they collectively represent a majority of use-cases and scales."><link data-react-helmet="true" rel="shortcut icon" href="/CoastTrain/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://dbuscombe-usgs.github.io/CoastTrain/docs/Version 1: March 2022/overview"><link data-react-helmet="true" rel="alternate" href="https://dbuscombe-usgs.github.io/CoastTrain/docs/Version 1: March 2022/overview" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://dbuscombe-usgs.github.io/CoastTrain/docs/Version 1: March 2022/overview" hreflang="x-default"><link rel="stylesheet" href="/CoastTrain/assets/css/styles.8fc74642.css">
<link rel="preload" href="/CoastTrain/assets/js/styles.6cf6f2dd.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/runtime~main.52019abb.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/main.18d5884b.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/1.b96507f5.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/2.d7141dbd.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/52.0aba4274.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/54.2a24e5db.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/935f2afb.783f72b1.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/17896441.8a20eeaa.js" as="script">
<link rel="preload" href="/CoastTrain/assets/js/01f1344f.295b4637.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#main" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle" type="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/CoastTrain/"><img src="/CoastTrain/img/Coast_train_logo.jpg" alt="CoastTrain" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/CoastTrain/img/Coast_train_logo.jpg" alt="CoastTrain" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title"></strong></a><a class="navbar__item navbar__link navbar__link--active" href="/CoastTrain/docs/intro">Project Information</a><a class="navbar__item navbar__link" href="/CoastTrain/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/Doodleverse/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Coast Train is made possible by the Doodleverse</a><div class="react-toggle displayOnlyInLargeViewport_GrZ2 react-toggle--disabled" role="button" tabindex="-1"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/CoastTrain/"><img src="/CoastTrain/img/Coast_train_logo.jpg" alt="CoastTrain" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/CoastTrain/img/Coast_train_logo.jpg" alt="CoastTrain" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title"></strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link navbar__link--active" href="/CoastTrain/docs/intro">Project Information</a></li><li class="menu__list-item"><a class="menu__link" href="/CoastTrain/blog">Blog</a></li><li class="menu__list-item"><a href="https://github.com/Doodleverse/" target="_blank" rel="noopener noreferrer" class="menu__link">Coast Train is made possible by the Doodleverse</a></li></ul></div></div></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_31aa"><div class="docSidebarContainer_3Kbt" role="complementary"><div class="sidebar_15mo"><div class="menu menu--responsive thin-scrollbar menu_Bmed"><button aria-label="Open menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_fgN0" width="24" height="24" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/CoastTrain/docs/intro">Coast Train: A Library of Labeled Coastal Images to Train Machine Learning Models</a></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Version 1: March 2022</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/CoastTrain/docs/Version 1: March 2022/overview">Overview</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/CoastTrain/docs/Version 1: March 2022/classes">Classes</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/CoastTrain/docs/Version 1: March 2022/data">Data</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/CoastTrain/docs/Version 1: March 2022/west-coast">Pacific Coast</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/CoastTrain/docs/Version 1: March 2022/east-coast">Atlantic Coast</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/CoastTrain/docs/Version 1: March 2022/gulf-coast">Gulf Coast</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/CoastTrain/docs/Version 1: March 2022/great-lakes">Great Lakes</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Version 2: Coming Soon!</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/CoastTrain/docs/Version 2: Coming Soon/overview">Overview</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Image Labeling</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/CoastTrain/docs/labeling/doodler">Doodler</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Admin</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/CoastTrain/docs/admin/how-to-contribute">[Coast Train Team] How to contribute</a></li></ul></li></ul></div></div></div><main class="docMainContainer_3ufF"><div class="container padding-vert--lg docItemWrapper_3FMP"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><header><h1 class="docTitle_3a4h">Overview</h1></header><div class="markdown"><p>While there are many potential types of imagery we could use, the Coast Train project has settled on the following types of imagery because they collectively represent a majority of use-cases and scales.</p><p>Version 1 contains Geospatial Imagery only. These data consist of spatial and time-series, and contain 1.2 billion labelled pixels, representing over 3.6 million hectares. We use a Human-in-the-Loop tool especially designed for rapid and reproducible Earth surface image segmentation. </p><p>The dataset consists of 10 data records. Each dataset is associated with a specific image type, and specific label categories. Among the sets, horizontal spatial resolutions range between 0.05m and 1m for orthomosaics, and either 10m or 15m for satellite imagery. All image sources are publicly available.</p><ol><li>NAIP (aerial)</li><li>Sentinel-2 (satellite)</li><li>Landsat-8 (satellite)</li><li>U.S. Geological Survey (USGS) Quadrangle (aerial)</li><li>Unmanned Aerial Survey (UAS) -derived (aerial) orthomosaic imagery. </li></ol><p>Each data record is characterized principally by the combination of image type and class set. The study was confined to locations within the conterminous United States (CONUS), and locations related to various historical and present USGS research objectives within coastal hazards and ecosystems research were prioritized. </p><p>We included a set of relatively recently published sets of high-resolution orthomosaic imagery created from aerial imagery collected from following a Structure-from-Motion workflow in addition to geospatial satellite imagery data available throughout CONUS. The orthomosaics are locationally specific data collectively represent muddy, sandy, and mixed-sand-gravel beaches and barrier islands, in developed and undeveloped settings.</p><p>The number of label categories varies between four and 12. The dataset consists of 1852 individual images, comprising 1.196 billion pixels, and representing a total of 3.63 million hectares of Earthâ€™s surface. Most image sets are composed of time-series from specific sites, ranging between two and 202 individual locations. Other imagery covers an area at one specific time. Using the labeling program Doodler49 that we created for creation of this and similar datasets50, the number of pixels annotated directly by a human labeler was just over 169 million, out of over 1192 million pixels classified in total, or just over 14 percent (Table 1, Figure 4). Each labeler performed on-the-fly quality assurance through diligent usage of the labeling tool.</p><h2 id="geospatial-imagery">Geospatial Imagery</h2><ol><li>NAIP
The dataset consists of 1-m NAIP imagery. There are 493 images depicting 366 unique locations.</li></ol><p>Cloudless 1-m NAIP orthomosaic imagery was collected at various times in summer between 2010 and 2018. </p><p>Images are either 3-band (RGB) or 1-band (near-infrared) of the same extent. For each jpg file, there is a .wld file (ESRI world file format) and a aux.xml file containing all relevant coordinate system reference information for that image.</p><p><img src="/CoastTrain/assets/images/example_coasttrain_naip_remapped-09f1daf8e7ee7c4793dca716bbd2eca4.png"></p><ol start="2"><li>Orthomosaics
The dataset consists of 5-cm orthomosaic imagery created from low altitude (&lt;100 meters above ground level) nadir imagery using SfM processing, with variable coverage. The large ortrhomosaics have been tiled into 1024x1024x3 pixel images in jpeg format. </li></ol><p><img src="/CoastTrain/assets/images/example_coasttrain_madeira_remapped-190d6be8c803bb524c4c501895a23778.png"></p><ol start="3"><li>Satellite imagery</li></ol><p>Sentinel-2 imagery was collected over the period 2017-2020, and Landsat-8 imagery over the period 2014-2020. All Landsat imagery were pan-sharpened using a method based on principal components of the 15-m panchromatic band, resulting in 3-band imagery with 15-m pixel size. Visible-band 10-m Sentinel-2 imagery was used. Visible-spectrum (blue, green, and red bands) imagery were labeled, which was necessary to identify all the various classes.</p><p><img src="/CoastTrain/assets/images/example_coasttrain_s2_4class-d3da59848cbb4d6a4401ef7f64a2e35b.png"></p><ol start="4"><li>Quads
USGS quadrangle imagery43 depict mud-dominated delta and wetland environments of the Mississippi delta in Louisiana, collected in summer 2008 and 2012. </li></ol><p>USGS Digital Ortho Quadrangle imagery of coastal wetlands in the Gulf. See <a href="https://www.usgs.gov/faqs/what-a-digital-orthophoto-quadrangle-doq-or-orthoimage?qt-news_science_products=0#qt-news_science_products">here</a></p><p><img src="/CoastTrain/assets/images/example_coasttrain_quads-a1667f5e53ec4603dedefd216b6f8649.png"></p><h2 id="summary-graphics">Summary graphics</h2><h3 id="inter-labeler-agreement">Inter-labeler Agreement</h3><p>We computed mean Intersection over Union (IoU) scores for quantifying inter-labeler agreement. We use 120 images across two datasets, namely NAIP (70 image pairs) and Sentinel-2 (50 image pairs), that have been labeled independently by our most experienced labelers</p><p>Figure: Frequency distribution of all images labeled by mean IoU scores, for the a) NAIP-11 class and b) Sentinel-2 11-class datasets. </p><p><img src="/CoastTrain/assets/images/agreement_stats_coasttrain_naip_s2_IOU-a67396bd4f139da96b80105077c81150.png"></p><h3 id="geographic-coverage">Geographic Coverage</h3><p>Collectively, the data records have been chosen to represent a wide variety of coastal environments, collectively spanning the geographic range 26 to 48 degrees N in latitude, and 69 to 123 degrees W in longitude. The majority of coastal states are represented. The final dataset contains numerous (but unequal) examples of coasts dominated by rocky cliffs, wetlands, saltmarshes, deltas, and beaches, including rural and urban locations, and low- and high-energy environments. </p><p>Figure: Geographical distribution of A) orthomosaic and B) satellite imagery, and C) the â€˜heatmapâ€™ of image locations, or the number of images in spatial bins.</p><p><img src="/CoastTrain/assets/images/Merged_maps_folium_ann2-7e475c692bef029444e25c9f8832f794.png"></p><h3 id="annotation-density">Annotation density</h3><p>The percentage of pixels directly annotated by a human also varies considerably among individual datasets. The percentage of pixels annotated and total pixels labeled are negatively correlated; labelers tend to annotate a larger proportion of lower-resolution scenes.</p><p>Figure: The size of the individual datasets, expressed as millions of total pixels labeled, computed as the product of the two horizontal label image dimensions, summed over all labeled images in each set. Percentage of pixels annotated by a human is computed as the product of the two horizontal label image dimensions and the proportion of the image labeled using the labeling program â€˜Doodlerâ€™, summed over all labeled images in each set. </p><p><img src="/CoastTrain/assets/images/Million_pixels_vs_percentage_doodled-19772810b3bd0a5788a925f18e02ded6.png"></p><h3 id="labeler-distributions">Labeler distributions</h3><p>The dataset was labeled by three main individuals (ID1, 2, and 3) and certain datasets were labeled by others (ID4 and ID5).</p><p>Figure: Frequency distribution of images labeled by unique labeler ID.</p><p><img src="/CoastTrain/assets/images/Label_all_million_pixels_datarecords_per_ID-aa15a8fa94e7a4812e96b0dd1af7f656.png"></p></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/dbuscombe-usgs/CoastTrain/edit/master/website/docs/Version 1: March 2022/overview.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" role="img" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-label="Edit page"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/CoastTrain/docs/intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Coast Train: A Library of Labeled Coastal Images to Train Machine Learning Models</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/CoastTrain/docs/Version 1: March 2022/classes"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Classes Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#geospatial-imagery" class="table-of-contents__link">Geospatial Imagery</a></li><li><a href="#summary-graphics" class="table-of-contents__link">Summary graphics</a><ul><li><a href="#inter-labeler-agreement" class="table-of-contents__link">Inter-labeler Agreement</a></li><li><a href="#geographic-coverage" class="table-of-contents__link">Geographic Coverage</a></li><li><a href="#annotation-density" class="table-of-contents__link">Annotation density</a></li><li><a href="#labeler-distributions" class="table-of-contents__link">Labeler distributions</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Docs</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/CoastTrain/docs/intro">Project Information</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Community</h4><ul class="footer__items"><li class="footer__item"><a href="https://dbuscombe-usgs.github.io/dash_doodler/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Doodler</a></li><li class="footer__item"><a href="https://github.com/Doodleverse" target="_blank" rel="noopener noreferrer" class="footer__link-item">The Doodleverse</a></li><li class="footer__item"><a href="https://coastalimagelabeler.science/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Coastal Image Labeler by Dr Evan Goldstein</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">More</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/CoastTrain/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/dbuscombe-usgs/dash_doodler" target="_blank" rel="noopener noreferrer" class="footer__link-item">Doodler github</a></li><li class="footer__item"><a href="https://www.makesense.ai/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Makesense.ai (an alternative way to segment imagery)</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">This website is written and maintained by Daniel Buscombe, Marda Science, LLC, contracted to the U.S. Geological Survey Pacific Coastal and Marine Science Center in Santa Cruz, CA, on behalf of the Coast Train team. Coast Train is funded by the U.S. Geological Survey Community for Data Integration, and is for the primary usage of U.S. Geological Survey scientists, researchers and affiliated colleagues working on coastal hazards, processes, and ecosystems research. Copyright Â© 2022 Marda Science, LLC. </div></div></div></footer></div>
<script src="/CoastTrain/assets/js/styles.6cf6f2dd.js"></script>
<script src="/CoastTrain/assets/js/runtime~main.52019abb.js"></script>
<script src="/CoastTrain/assets/js/main.18d5884b.js"></script>
<script src="/CoastTrain/assets/js/1.b96507f5.js"></script>
<script src="/CoastTrain/assets/js/2.d7141dbd.js"></script>
<script src="/CoastTrain/assets/js/52.0aba4274.js"></script>
<script src="/CoastTrain/assets/js/54.2a24e5db.js"></script>
<script src="/CoastTrain/assets/js/935f2afb.783f72b1.js"></script>
<script src="/CoastTrain/assets/js/17896441.8a20eeaa.js"></script>
<script src="/CoastTrain/assets/js/01f1344f.295b4637.js"></script>
</body>
</html>